{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Contents<font/>\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "1. **Jupyter setup <br>**\n",
    "2. **Data Load <br>**\n",
    "3. **Exploratory Data Analysis <br>**\n",
    "    * **Identify Variables and Variable Types and Clean**\n",
    "    * **Derive Variables**\n",
    "    * **Identify and Handle Outliers**\n",
    "    * **Inspect Distributions**\n",
    "    * **Remove Outlier Rows and Rerun Distribution Plots** <br><br>\n",
    "4. **Regression Model Builds**\n",
    "\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Jupyter Setup<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Data Load<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'kc_house_data.csv' does not exist: b'kc_house_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9e94bdf23c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morig_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kc_house_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'kc_house_data.csv' does not exist: b'kc_house_data.csv'"
     ]
    }
   ],
   "source": [
    "orig_df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Exploratory Data Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify variables and variable Types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inital inspection:\n",
    "\n",
    "1. Three variables have null values: **`waterfront`**, **`view`** and **`yr_renovated`**\n",
    "2. **`date`** looks to be a string variable instead of datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect each variable individually, looking for any further integrity issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color=green>id</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would it be possible to use **`id`** as the index column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, as there are duplicate ids within the column which indicates that the same property has been sold multiple times within the time frame of the dataset.\n",
    "\n",
    "A follow up question is whether it would be worth creating a derived variable that flags those properties that have been sold multiple times to be used as possible input variable fo rthe regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vc = pd.DataFrame(df['id'].value_counts())  # Check how many times properties appear within the dataset\n",
    "id_vc = id_vc.reset_index()\n",
    "id_vc.columns\n",
    "\n",
    "number_of_unique_ids = len(id_vc.loc[id_vc['id'] > 1].sort_values(by = 'id', ascending = False))\n",
    "\n",
    "print('{}'.format(round((number_of_unique_ids / len(id_vc))*100, 2)) + '% of properties were sold multiple times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties sold multiple times only account for 0.82% of all unique properties within the dataset and therefore there is no real value in deriving a variable to flag 'number of times sold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><font color=green>date</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].describe()\n",
    "type(df['date'][0])\n",
    "\n",
    "df['date'].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **`date`** variable is stored as a str object and needs to be converted to **datetime** format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the modification has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>price</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['price'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`price`** variable type is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>bedrooms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bedrooms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['bedrooms'][0]))\n",
    "df['bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bedrooms`** variable is of correct type but there does seem to be some extreme values: 33, 11 and 10\n",
    "\n",
    "The variable is also clearly a categorical variable.\n",
    "\n",
    "Outliers will be dealt with later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>bathrooms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bathrooms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['bathrooms'][0]))\n",
    "df['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bathrooms`** variable is of correct type but there could be possible extreme outliers of bathrooms per bedroom > 6\n",
    "\n",
    "This variable can potentially be considered as a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_living</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_living'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['sqft_living'][0]))\n",
    "df['sqft_living'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`sqft_living`** variable is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_lot</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_lot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['sqft_lot'][0]))\n",
    "df['sqft_lot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`sqft_lot`** variable is of correct type but there does seem to be some extreme values: 1,651,359 sq ft.<br>\n",
    "\n",
    "Outliers will be dealt with later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>floors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['floors'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['floors'][0])\n",
    "df['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`floors`** is of correct type\n",
    "\n",
    "This variable is a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>waterfront</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **`waterfront`** variable has 2,376 missing values\n",
    "\n",
    "This variable is a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['waterfront'][0]))\n",
    "\n",
    "#df['waterfront'] = df['waterfront'].astype('int64')\n",
    "\n",
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the variable is of correct boolean type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the missing will need to be imputed with a placeholder value: **9.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'] = df['waterfront'].fillna(9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the imputation has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'] = df['waterfront'].astype('int64')\n",
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>view</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **`view`** variable has 63 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['view'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the variable is of correct numerical type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the missing will need to be imputed with a placeholder value: median of non-null **`view`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_median = df['view'].loc[df['view'].isna() == False].median()\n",
    "print(view_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'] = df['view'].fillna(int(view_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the imputation has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'] = df['view'].astype('int64')\n",
    "\n",
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable is a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>condition</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['condition'].describe(),'\\n')\n",
    "print(type(df['condition'][0]))\n",
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`condition`** is of correct type\n",
    "\n",
    "This variable is a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>grade</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['grade'].describe(), '\\n')\n",
    "print(type(df['grade'][0]))\n",
    "df['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`grade`** is of correct type\n",
    "\n",
    "This variable is a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_above</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sqft_above'].describe(), '\\n')\n",
    "print(type(df['sqft_above'][0]))\n",
    "df['sqft_above'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_basement</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sqft_basement'].describe(), '\\n')\n",
    "print(type(df['sqft_basement'][0]))\n",
    "df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a random '?' value within the **`sqft_basement`** variable and needs to be treated as a missing value but since we want to convert the variable to of numerical type we need to replace the '?' with a numerical missing value placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First need to check the median value for all values != '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_basement_median = df['sqft_basement'].loc[df['sqft_basement'] != '?'].median()\n",
    "print(sqft_basement_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace '?' with '0.0':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].replace('?',str(sqft_basement_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The **`sqft_basement`** variable is stored as a str needs to be converted into a integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].apply(lambda x: float(x)).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sqft_basement'].describe(), '\\n')\n",
    "print(df['sqft_basement'].isna().sum(), '\\n')\n",
    "df['sqft_basement'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>yr_built</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['yr_built'].describe(), '\\n')\n",
    "print(type(df['yr_built'][0]))\n",
    "df['yr_built'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be usefule to bin this variable into decades.\n",
    "\n",
    "which will also make it a categorical variable.\n",
    "\n",
    "Will be done later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>yr_renovated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['yr_renovated'].describe(), '\\n')\n",
    "print(type(df['yr_renovated'][0]))\n",
    "df['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Missing values seem to exist\n",
    "* a value of 0.0 is assumed to mean not renovated\n",
    "* Categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3,842 missing values need to be imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First need to check whether 2050.0 will be a safe choice for a missing value placeholder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['yr_renovated'].loc[df['yr_renovated'] != 0.0].unique(), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2050 will be a safe choice to represent missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'] = df['yr_renovated'].fillna(2050.0)\n",
    "df['yr_renovated'] = df['yr_renovated'].astype('int64')\n",
    "# verify imputation\n",
    "df['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>zipcode</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['zipcode'].describe(), '\\n')\n",
    "print(df['zipcode'].head(), '\\n')\n",
    "print(type(df['zipcode'][0]), '\\n')\n",
    "print(df['zipcode'].value_counts(), '\\n')\n",
    "df['zipcode'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`zipcode`** is of correct type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green>lat</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['lat'].describe(), '\\n')\n",
    "print(df['lat'].head(), '\\n')\n",
    "print(type(df['lat'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`lat`** is of correct type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>long</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['long'].describe(), '\\n')\n",
    "print(df['long'].head(), '\\n')\n",
    "print(type(df['long'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`long`** is of correct type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_living15</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sqft_living15'].describe(), '\\n')\n",
    "print(df['sqft_living15'].head(), '\\n')\n",
    "print(type(df['sqft_living15'][0]), '\\n')\n",
    "df['sqft_living15'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>sqft_lot15</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sqft_lot15'].describe(), '\\n')\n",
    "print(df['sqft_lot15'].head(), '\\n')\n",
    "print(type(df['sqft_lot15'][0]), '\\n')\n",
    "df['sqft_lot15'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original structure of the dataframe:\n",
    "\n",
    "<img src=\"orig_df_info.png\" width = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is the new structure after cleaning process cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=red>Cleaned Dataset Formats</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `day_of_week`, `month`, `quarter` derived from `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be useful to explor whether the time of year or week has any impact on the price of a property. THerefore the day, month and quarter will need to be extracted from the **`date`** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Useful to extract the day, month and quarter from the date variable:\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "df['quarter'] = df['date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.bar(df['date'].value_counts().index, df['date'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.bar(df['day_of_week'].value_counts().index, df['day_of_week'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.bar(df['month'].value_counts().index, df['month'].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.bar(df['quarter'].value_counts().index, df['quarter'].value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `distance_from_town_centre` derived from `long` and `lat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a fixed longitude and latitude coordinates of [-122.3341, 47.6106] to represent the city centre of Seattle. We will derive a new variable that calculates the distance from the property to the city centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_calc(long_lat, city_centre_long_lat = [-122.3341, 47.6106]):\n",
    "    \n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    city_centre_lon = radians(city_centre_long_lat[0])\n",
    "    city_centre_lat = radians(city_centre_long_lat[1])\n",
    "    \n",
    "    addres_lon = radians(float(long_lat.split(',')[0]))\n",
    "    address_lat = radians(float(long_lat.split(',')[1]))\n",
    "\n",
    "    dlon = city_centre_lon - addres_lon\n",
    "    dlat = city_centre_lat - address_lat\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(city_centre_lat) * cos(address_lat) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_lat_coords'] = df[\"long\"].map(str) + \",\" + df[\"lat\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_from_city_centre'] = df['long_lat_coords'].apply(lambda x: distance_calc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['zipcode','long', 'lat', 'dist_from_city_centre']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,df.columns != 'long_lat_coords'] # Drop this column as it is not needed for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `livingsqft_lotsqft_ratio` derived from `sqft_living` and `sqft_lot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been noted that there are instances where the size of the living space (**`sqft_living`**) is considerably smaller than the size of the lot **`sqft_lot`**. So it will be useful to create a metric that measures the ratio of the living to lot size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['livingsqft_lotsqft_ratio'] = df['sqft_living']/df['sqft_lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['sqft_living', 'sqft_lot', 'livingsqft_lotsqft_ratio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `yrs_since_renovation` derived from `yr_renovated`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a measure of **`yr_renovated`** that is a standardised measure regardless of the year in which the property was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundown(x):\n",
    "    return int(math.floor(x / 10.0)) * 10\n",
    "\n",
    "def yrs_since_renov(row):\n",
    "    if (row['yr_renovated'] not in (0, 2050)) and (row['date'].year > row['yr_renovated']):\n",
    "        return roundown(row['date'].year - row['yr_renovated'])\n",
    "    elif row['yr_renovated'] == 2050:\n",
    "        return -2\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "df['yrs_since_renovation'] = df.apply(yrs_since_renov, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['yrs_since_renovation'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `decade_built` derived from `yr_built`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be useful to bin the **`yr_built`** variable for exploration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decade_built'] = df['yr_built'].apply(lambda x: roundown(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decade_built'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy alternatives of categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the independent variables are categorical by nature and so it is required to convert the to dummy vasriables using the one-hot encoding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade', 'decade_built', 'yrs_since_renovation']] = df.loc[:,['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade', 'decade_built', 'yrs_since_renovation']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_dict = {'empty': None}\n",
    "\n",
    "for i in ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade', 'decade_built', 'yrs_since_renovation']:\n",
    "  \n",
    "    cat_var_dict[str(i)+'_dummies'] = pd.get_dummies(df[str(i)], prefix='d_' + str(i)[:5], drop_first=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cat_var_dict.keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, cat_var_dict['bedrooms_dummies'], cat_var_dict['bathrooms_dummies'], cat_var_dict['floors_dummies'], cat_var_dict['waterfront_dummies'], cat_var_dict['view_dummies'], cat_var_dict['condition_dummies'],\n",
    "             cat_var_dict['grade_dummies'], cat_var_dict['decade_built_dummies'], cat_var_dict['yrs_since_renovation_dummies']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_dummies = df.loc[:,['id',\n",
    " 'date',\n",
    " 'price',\n",
    " 'bedrooms',\n",
    " 'bathrooms',\n",
    " 'sqft_living',\n",
    " 'sqft_lot',\n",
    " 'floors',\n",
    " 'waterfront',\n",
    " 'view',\n",
    " 'condition',\n",
    " 'grade',\n",
    " 'sqft_above',\n",
    " 'sqft_basement',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'sqft_living15',\n",
    " 'sqft_lot15',\n",
    " 'month',\n",
    " 'quarter',\n",
    " 'dist_from_city_centre',\n",
    " 'livingsqft_lotsqft_ratio',\n",
    " 'yrs_since_renovation',\n",
    " 'decade_built']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axes2 = plt.subplots(5, 5, figsize = (20,40))\n",
    "axes2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n in range(1,24):\n",
    "    \n",
    "    i = df_no_dummies.dtypes.index[n-1]\n",
    "    \n",
    "    row = (n-1)//5\n",
    "    col = (n-1)%5\n",
    "    \n",
    "    if str(type(df_no_dummies[str(i)][0])) in [\"<class 'numpy.float64'>\", \"<class 'numpy.int64'>\"]:\n",
    "        ax = axes2[row][col]\n",
    "        ax.boxplot(df[str(i)])\n",
    "        ax.set_title('{}'.format(i))\n",
    "    else:   \n",
    "        ax = axes2[row][col]\n",
    "        ax.set_title('{}'.format(i))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial observations:\n",
    "\n",
    "* **`bedrooms`**, **`sqft_lot`**, **`sqft_basement`**, **`sqft_lot15`** have clear extreme outliers which require removing/imputation\n",
    "* **`bathrooms`** may have possible outliers of >6\n",
    "* boxplots for **`view`**, **`yr_renovated`** have been distorted due to the previous step of imputing values for the missing observations with 9999.0. The box plot will have to be re-run without these imputed observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axes2 = plt.subplots(1, 2, figsize = (10,10))\n",
    "axes2.shape\n",
    "\n",
    "col = (-1)\n",
    "for n in range(1,27):\n",
    "    \n",
    "    i = df.dtypes.index[n-1]\n",
    "    \n",
    "    row = 1\n",
    "    \n",
    "    \n",
    "    if i in ['view']:\n",
    "        \n",
    "        col += 1\n",
    "        a = [x for x in df[str(i)].value_counts().index if x != 9999.0]\n",
    "        b = [df[str(i)].value_counts().ix[x] for x in df[str(i)].value_counts().index if x != 9999.0]\n",
    "        \n",
    "\n",
    "        ax = axes2[col]\n",
    "        ax.boxplot(a)\n",
    "        ax.set_title('{}'.format(i))\n",
    "        \n",
    "    elif i in ['yr_renovated']:\n",
    "        \n",
    "        col += 1\n",
    "        a = [x for x in df[str(i)].value_counts().index if (x != 9999.0) and (x != 0.0)]\n",
    "        b = [df[str(i)].value_counts().ix[x] for x in df[str(i)].value_counts().index if x != 9999.0]\n",
    "        \n",
    "       \n",
    "        ax = axes2[col]\n",
    "        ax.boxplot(a)\n",
    "        ax.set_title('{}'.format(i));\n",
    "    else:   \n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(9, 3, figsize = (20,40))\n",
    "axes.shape\n",
    "\n",
    "\n",
    "for n in range(1,27):\n",
    "    \n",
    "    i = df.dtypes.index[n-1]\n",
    "    \n",
    "    row = (n-1)//3\n",
    "    col = (n-1)%3\n",
    "    \n",
    "    if len(df[str(i)].unique()) > 50:\n",
    "        #continue\n",
    "        ax = axes[row][col]\n",
    "        ax.set_title('{}'.format(i))\n",
    "        ax.hist(df[str(i)], bins = 100)\n",
    "        continue\n",
    "    \n",
    "    a = [x for x in df[str(i)].value_counts().index if x != 9999.0]\n",
    "    b = [df[str(i)].value_counts().ix[x] for x in df[str(i)].value_counts().index if x != 9999.0]\n",
    "        \n",
    "    ax = axes[row][col]\n",
    "    ax.bar(a, b)\n",
    "    ax.set_title('{}'.format(i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outl_vars = ['bedrooms', 'sqft_lot', 'sqft_basement', 'sqft_lot15', 'bathrooms']\n",
    "def remove_outliers_and_plot_bars(list_of_vars):\n",
    "    \n",
    "    fig2, axes2 = plt.subplots(1, 5, figsize = (20,5))\n",
    "\n",
    "    col = (-1)\n",
    "    \n",
    "    for i in list_of_vars:\n",
    "        \n",
    "            \n",
    "        col += 1\n",
    "    \n",
    "        pcntle = np.percentile(df[str(i)], 75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(df[str(i)].unique()) > 50:\n",
    "            ax = axes2[col]\n",
    "            ax.hist(df[str(i)].loc[df[str(i)] < pcntle], bins = 30)\n",
    "            ax.set_title('{}'.format(i))\n",
    "    \n",
    "            continue\n",
    "    \n",
    "        else:\n",
    "\n",
    "            a = [x for x in df[str(i)].value_counts().index if x < pcntle]\n",
    "            b = [df[str(i)].value_counts().ix[x] for x in df[str(i)].value_counts().index if x < pcntle]\n",
    "            \n",
    "            ax = axes2[col]\n",
    "            ax.bar(a, b)\n",
    "            ax.set_title('{}'.format(i))\n",
    "    \n",
    "    col = (-1)\n",
    "        \n",
    "remove_outliers_and_plot_bars(outl_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3, axes3 = plt.subplots(9, 3, figsize = (25,40))\n",
    "axes3.shape\n",
    "\n",
    "\n",
    "for n in range(1,27):\n",
    "    \n",
    "    i = df.dtypes.index[n-1]\n",
    "    \n",
    "    row = (n-1)//3\n",
    "    col = (n-1)%3\n",
    "    \n",
    "    if str(type(df[str(i)][0])) in [\"<class 'numpy.float64'>\", \"<class 'numpy.int64'>\"]:\n",
    "        \n",
    "        if (len(df[str(i)].unique()) > 12) and (str(i) not in ['bathrooms']):\n",
    "        \n",
    "            ax = axes3[row][col]\n",
    "            ax.scatter(df[str(i)], df['price'])\n",
    "            ax.set_title('{}'.format(i) + ' vs price')\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            ax = axes3[row][col]\n",
    "            sns.boxplot(str(i), 'price', data=df, ax=ax)\n",
    "            ax.set_title('{}'.format(i) + ' vs price')\n",
    "    else:   \n",
    "        ax = axes3[row][col]\n",
    "        ax.set_title('{}'.format(i))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outl_vars = ['sqft_living', 'sqft_lot', 'sqft_basement', 'sqft_lot15', 'sqft_living15'\n",
    "             , 'sqft_above', 'yr_built', 'dist_from_city_centre'\n",
    "             ,'livingsqft_lotsqft_ratio']\n",
    "\n",
    "\n",
    "for i in outl_vars:\n",
    "    \n",
    "    df[(str(i) + '_bins')] = pd.cut(df[str(i)], 10, labels = list(range(1,11)))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def remove_outliers_and_plot_grouped_boxes(list_of_vars):\n",
    "    \n",
    "    fig2, axes2 = plt.subplots(3, 3, figsize = (20,20))\n",
    "\n",
    "   \n",
    "    n = (-1)\n",
    "    for i in list_of_vars:\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        row = (n)//3\n",
    "        col = (n)%3\n",
    "        \n",
    "        ax = axes2[row][col]\n",
    "        sns.boxplot((str(i) + '_bins'), 'price', data=df, ax=ax)\n",
    "        ax.set_title('{}'.format(str(i)) + ' vs price')\n",
    "    \n",
    "\n",
    "    n = (-1)  \n",
    "        \n",
    "remove_outliers_and_plot_grouped_boxes(outl_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('yrs_since_renovation', 'price', data=df).set_title('yr_renovated vs price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial observations:**\n",
    "\n",
    "The following variables show some sort of correlation upon price (observed either in the scatter plots or the grouped box-plots):\n",
    "\n",
    "* **`sqft_living`**\n",
    "* **`sqft_lot`**\n",
    "* **`bedrooms`**\n",
    "* **`bathrooms`**\n",
    "* **`floors`**\n",
    "* **`condition`**\n",
    "* **`sqft_living15`**\n",
    "* **`grade`**\n",
    "* **`dist_from_city_centre`**\n",
    "* **`livingsqft_lotsqft_ratio`**\n",
    "* **`yrs_since_renovation`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to confirm by calculating Pearson's Correlation for the above variables against **`price`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "for i in ['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms', 'floors', 'condition', 'sqft_living15', 'grade', 'dist_from_city_centre', 'livingsqft_lotsqft_ratio', 'yrs_since_renovation']:\n",
    "\n",
    "    print('{} :'.format(i) + str(round(pearsonr(df[i], df['price'])[0], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pearson's correlation the following variables show the strongest correlation with price:\n",
    "\n",
    "* **`sqft_living`**   => 0.7\n",
    "* **`bathrooms`**     => 0.51\n",
    "* **`sqft_living15`** => 0.59\n",
    "* **`grade`**         => 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps will remove outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['bedrooms'] < 33] # Obvious outlier from the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['sqft_lot'] < 1651359] # Obvious outlier from the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers = pd.DataFrame(None)\n",
    "\n",
    "# below loop will loop through all the variables that have previously been identified as having upper outliers and will\n",
    "# flag the observations to which the outliers belong in the dataset (only upper outliers)\n",
    "\n",
    "for i in ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot'\n",
    "          ,'floors', 'sqft_above','sqft_basement'\n",
    "          ,'sqft_living15', 'sqft_lot15']:\n",
    "    \n",
    "    data_mean, data_std = np.mean(df[str(i)]), np.std(df[str(i)])\n",
    "    # identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    upper = data_mean + cut_off\n",
    "    df_without_outliers[str(i) + '_outlier_flag'] = (df[str(i)] >= upper)\n",
    "        \n",
    "        \n",
    "df_without_outliers = df_without_outliers.replace(True,np.nan).dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_keep = df_without_outliers.index\n",
    "\n",
    "print(indexes_to_keep)\n",
    "len(indexes_to_keep)\n",
    "\n",
    "\n",
    "# highlight observations that do not have any outliers across any columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows = df.ix[indexes_to_keep]\n",
    "\n",
    "len(df_without_outlier_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun exploratory scatter plots and boxplots from the previous section to compare how the correlations differ with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3, axes3 = plt.subplots(7, 4, figsize = (25,40))\n",
    "axes3.shape\n",
    "\n",
    "\n",
    "for n in range(1,29):\n",
    "    \n",
    "    i = df_without_outlier_rows.dtypes.index[n-1]\n",
    "    \n",
    "    row = (n-1)//4\n",
    "    col = (n-1)%4\n",
    "    \n",
    "    if str(type(df_without_outlier_rows[str(i)][0])) in [\"<class 'numpy.float64'>\", \"<class 'numpy.int64'>\"]:\n",
    "        \n",
    "        if (len(df_without_outlier_rows[str(i)].unique()) > 12) and (str(i) not in ['bathrooms']):\n",
    "        \n",
    "            ax = axes3[row][col]\n",
    "            ax.scatter(df_without_outlier_rows[str(i)], df_without_outlier_rows['price'])\n",
    "            ax.set_title('{}'.format(i) + ' vs price')\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            ax = axes3[row][col]\n",
    "            sns.boxplot(str(i), 'price', data=df_without_outlier_rows, ax=ax)\n",
    "            ax.set_title('{}'.format(i) + ' vs price')\n",
    "    else:   \n",
    "        ax = axes3[row][col]\n",
    "        ax.set_title('{}'.format(i))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outl_vars = ['sqft_lot', 'sqft_basement', 'sqft_lot15', 'sqft_living15'\n",
    "             ,'sqft_above', 'yr_built', 'dist_from_city_centre'\n",
    "             ,'livingsqft_lotsqft_ratio']\n",
    "\n",
    "\n",
    "for i in outl_vars:\n",
    "    \n",
    "    df_without_outlier_rows[(str(i) + '_bins')] = pd.cut(df_without_outlier_rows[str(i)], 10, labels = list(range(1,11)))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def remove_outliers_and_plot_grouped_boxes(list_of_vars):\n",
    "    \n",
    "    fig2, axes2 = plt.subplots(3, 3, figsize = (20,40))\n",
    "\n",
    "   \n",
    "    n = (-1)\n",
    "    for i in list_of_vars:\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        row = (n)//3\n",
    "        col = (n)%3\n",
    "        \n",
    "        ax = axes2[row][col]\n",
    "        sns.boxplot((str(i) + '_bins'), 'price', data=df_without_outlier_rows, ax=ax)\n",
    "        ax.set_title('{}'.format(str(i)) + ' vs price')\n",
    "    \n",
    "\n",
    "    n = (-1)  \n",
    "        \n",
    "remove_outliers_and_plot_grouped_boxes(outl_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('yrs_since_renovation', 'price', data=df_without_outlier_rows).set_title('yr_renovated vs price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms', 'floors', 'condition', 'sqft_living15', 'grade', 'dist_from_city_centre', 'livingsqft_lotsqft_ratio', 'yrs_since_renovation', 'view']:\n",
    "\n",
    "    print('{} :'.format(i) + str(round(pearsonr(df_without_outlier_rows[i], df_without_outlier_rows['price'])[0], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare pearson's correlation before outliers removed and after:\n",
    "\n",
    "* **`sqft_living`**&ensp;&ensp;&emsp;&emsp;&emsp;=> 0.7,&emsp;&emsp;0.62\n",
    "* **`bathrooms`**&emsp;&emsp;&emsp;&emsp;&emsp;=> 0.51,&emsp;&emsp;0.4\n",
    "* **`sqft_living15`**&emsp;&emsp;=> 0.59,&emsp;&emsp;0.55\n",
    "* **`grade`**&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;=> 0.67,&emsp;&emsp;0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real change in correlation scores except with **`sqft_living`** and **`bathrooms`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Regression Model Build<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to create four regression models from the dataset (with outliers removed):\n",
    "\n",
    "* 1. One master model that seeks to identify the variables that most impact the price of the property. This model will use the variables highlighted as having the greatest correlation with **`price`** <br><br>\n",
    "* 2. three sub models that seek to identify the relative impact of specific variables upon **`price`** in order to answer the following questions:<br><br>\n",
    "\n",
    "    * Which structural features have the largest impact on price?\n",
    "    * Does the cosmetic condition affect price?\n",
    "    * Does the size of property and size of land affect price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create three datasets for each question:<br>\n",
    "    \n",
    "    1) Which structural features make the largest impact on price?\n",
    "    2) Does cosmetic condition affect price?\n",
    "    3) Does size of property and land affect price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using the dummy converted variables instead of the original categorical variables for **`bathrooms`**, **`bedrooms`**, **`yrs_since_renovation`**, **`grade`** and **`condition`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows = df_without_outlier_rows.rename(columns={\"d_yrs_s_-1\": \"d_yrs_s_minus1\"}) \n",
    "# clean up a naming convention in one specific variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the 4 datasets to input into our regression model builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall = df_without_outlier_rows.loc[:,['price', 'd_bathr_1',\n",
    "       'd_bathr_2', 'd_bathr_3', 'd_grade_4',\n",
    "       'd_grade_5', 'd_grade_6', 'd_grade_7', 'd_grade_8', 'd_grade_9',\n",
    "       'd_grade_10', 'd_grade_11', 'd_grade_12', 'sqft_living', 'sqft_living15']]\n",
    "\n",
    "\n",
    "df_structural = df_without_outlier_rows.loc[:,['price', 'd_bedro_2', 'd_bedro_3',\n",
    "       'd_bedro_4', 'd_bedro_5', 'd_bedro_6', 'd_bathr_1',\n",
    "       'd_bathr_2', 'd_bathr_3', 'd_yrs_s_minus1', 'd_yrs_s_0', 'd_yrs_s_10',\n",
    "       'd_yrs_s_20', 'd_yrs_s_30', 'd_yrs_s_40', 'd_yrs_s_50', 'd_yrs_s_60',\n",
    "       'd_yrs_s_70', 'd_yrs_s_80']]\n",
    "\n",
    "df_cosmetic = df_without_outlier_rows.loc[:,['price', 'd_condi_2', 'd_condi_3', 'd_condi_4', 'd_condi_5', 'd_yrs_s_minus1', 'd_yrs_s_0', 'd_yrs_s_10',\n",
    "       'd_yrs_s_20', 'd_yrs_s_30', 'd_yrs_s_40', 'd_yrs_s_50', 'd_yrs_s_60',\n",
    "       'd_yrs_s_70', 'd_yrs_s_80']]\n",
    "\n",
    "df_size = df_without_outlier_rows.loc[:,['price', 'sqft_living', 'sqft_lot', 'livingsqft_lotsqft_ratio']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for multicollinearity between predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_without_outlier_rows.loc[:,['sqft_living', 'sqft_living15', 'bathrooms', 'grade']]\n",
    "\n",
    "pd.plotting.scatter_matrix(a,figsize  = [15, 15]);\n",
    "plt.show()\n",
    "\n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(a.corr(), center=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to exclude **`sqft_living`** from the regrrssionmodel build as it is highly correlated with the **`sqft_living15`**, **`bathrooms`**, **`grade`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "predictors = df_overall.drop(['price', 'sqft_living', 'd_grade_4',        # build model on just 'number of bathrooms'\n",
    "       'd_grade_5', 'd_grade_6', 'd_grade_7', 'd_grade_8', 'd_grade_9',\n",
    "       'd_grade_10', 'd_grade_11', 'd_grade_12', 'sqft_living15'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_overall).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "predictors = df_overall.drop(['price', 'sqft_living', 'd_grade_4',        # build model on 'number of bathrooms'\n",
    "       'd_grade_5', 'd_grade_6', 'd_grade_7', 'd_grade_8', 'd_grade_9',   # and 'sqft_living15'\n",
    "       'd_grade_10', 'd_grade_11', 'd_grade_12'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_overall).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "predictors = df_overall.drop(['price', 'sqft_living'],                   # build model on number of bathrooms,\n",
    "             axis=1)                                                     # sqft_living15 and grade\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_overall).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = **0.46**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 - Which structural features make the largest impact on price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structural.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'number of bedrooms' only\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_structural.drop(['price', 'd_bathr_1', 'd_bathr_2', 'd_bathr_3', 'd_yrs_s_minus1',\n",
    "       'd_yrs_s_0', 'd_yrs_s_10', 'd_yrs_s_20', 'd_yrs_s_30', 'd_yrs_s_40',\n",
    "       'd_yrs_s_50', 'd_yrs_s_60', 'd_yrs_s_70', 'd_yrs_s_80'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_structural).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'number of bedrroms' and 'number of bathrooms'\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_structural.drop(['price', 'd_yrs_s_minus1',\n",
    "       'd_yrs_s_0', 'd_yrs_s_10', 'd_yrs_s_20', 'd_yrs_s_30', 'd_yrs_s_40',\n",
    "       'd_yrs_s_50', 'd_yrs_s_60', 'd_yrs_s_70', 'd_yrs_s_80'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_structural).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'number of bedrooms', 'number of bathrooms' and 'yrs since renovated'\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_structural.drop(['price'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_structural).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = **0.2**\n",
    "\n",
    "making structural changes to a property such as adding a bathroom(s), bedroom(s) or simplty renovating only accounts for 20% in the change in price of a property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 - How much impact does cosmetic condition have on price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosmetic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'condition' only\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_cosmetic.drop(['price',\n",
    "       'd_yrs_s_minus1', 'd_yrs_s_0', 'd_yrs_s_10', 'd_yrs_s_20', 'd_yrs_s_30',\n",
    "       'd_yrs_s_40', 'd_yrs_s_50', 'd_yrs_s_60', 'd_yrs_s_70', 'd_yrs_s_80'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_cosmetic).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'condition' and 'yrs since renovation'\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_cosmetic.drop(['price'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_cosmetic).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = **0.02**\n",
    "\n",
    "making cosmetic improvements to a property such as improving condition or simply renovating only accounts for 2% in the change in price of a property. Minimal impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 - Are higher prices associated with larger properties, larger land or both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_without_outlier_rows.loc[:,['sqft_living', 'sqft_lot', 'livingsqft_lotsqft_ratio']]\n",
    "\n",
    "pd.plotting.scatter_matrix(a,figsize  = [15, 15]);\n",
    "plt.show()\n",
    "\n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'living sqft' and 'lot sqft'\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_size.drop(['price', 'livingsqft_lotsqft_ratio'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_size).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on 'living sqft - lot sqft ratio' only\n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_size.drop(['price', 'sqft_living', 'sqft_lot'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_size).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared (**`sqft_living`**, **`sqft_lot`**) = **0.39** <br>\n",
    "R-squared (**`livingsqft_lotsqft_ratio`**) = **0.04**\n",
    "\n",
    "size of living space have a much greater association with price than the actual size of land"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of obtaining the highest R-squared possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only considering variables that exhibited some level of correlation with price\n",
    "\n",
    "df_for_pairwise = df_without_outlier_rows.loc[:,['price', 'sqft_living',\n",
    "       'sqft_lot',\n",
    "       'sqft_above', 'sqft_basement',\n",
    "       'sqft_living15', 'sqft_lot15', 'month',\n",
    "       'dist_from_city_centre', 'livingsqft_lotsqft_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pairwise.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_for_pairwise.corr()) > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(df_for_pairwise.corr(), center=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding variables that showed high multicollinearity\n",
    "\n",
    "df_final = df_without_outlier_rows.loc[:,['price', 'sqft_living',\n",
    "       'sqft_lot',\n",
    "       'month',\n",
    "       'dist_from_city_centre',\n",
    "        'd_bedro_2', 'd_bedro_3',\n",
    "       'd_bedro_4', 'd_bedro_5', 'd_bedro_6', 'd_bathr_1',\n",
    "       'd_bathr_2', 'd_bathr_3', 'd_bathr_4', 'd_bathr_5', 'd_floor_2', 'd_floor_3', 'd_water_1',\n",
    "       'd_water_9', 'd_view_1', 'd_view_2', 'd_view_3', 'd_view_4',\n",
    "       'd_condi_2', 'd_condi_3', 'd_condi_4', 'd_condi_5', 'd_decad_1910',\n",
    "       'd_decad_1920', 'd_decad_1930', 'd_decad_1940', 'd_decad_1950',\n",
    "       'd_decad_1960', 'd_decad_1970', 'd_decad_1980', 'd_decad_1990',\n",
    "       'd_decad_2000', 'd_decad_2010', 'd_yrs_s_minus1', 'd_yrs_s_0',\n",
    "       'd_yrs_s_10', 'd_yrs_s_20', 'd_yrs_s_30', 'd_yrs_s_40', 'd_yrs_s_50',\n",
    "       'd_yrs_s_60', 'd_yrs_s_70', 'd_yrs_s_80']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "predictors = df_final.drop(['price'], axis=1)\n",
    "pred_sum = '+'.join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum\n",
    "\n",
    "model = ols(formula=formula, data=df_final).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = **0.63**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisations for Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sqft_lot = sns.scatterplot(x=\"sqft_living\", y=\"sqft_lot\", hue = 'zipcode' , data=df_without_outlier_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
